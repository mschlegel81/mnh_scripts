USE curveSorting;

//*Returns a naive partitioning of L based on function neighborhood
private naivePartitioning(L:List)->begin
  local rest:=L.map((entry)->assert(entry.isIntList(4)) orElse entry).toSet;
  local clusters:=[];
  while(rest.size>0,
    begin
      local part:=[rest.toList.head];
      rest>>part[0];
      local newOnes:=part.neighborhood.intersect(rest);
      while (newOnes.size>0,begin
        part|=newOnes;
        newOnes.each(n,rest>>n);
        newOnes:=newOnes.neighborhood.intersect(rest);
      end);
      clusters||=part;
    end);
  print('Found ',clusters.size,' clusters');
  clusters;
end;

//*Returns [shiftedDist,shift] for two collections
//*The shift must be applied to the second collection
private getShiftForStitching(c0:Collection,c1:Collection)->begin
  c0.each(i0,begin
    local deltas:=c1.map((i1)->i1-i0);
    local shifts:=-512*round(deltas/512);
    deltas:=(deltas+shifts).map(::euklideanNorm);
    local best:=argMin(deltas);
    local result:=[deltas[best],shifts[best]];
    result[0]=0 ? return note('Early abort ',result) orElse result : result;
  end,min);
end;

//*Has the same general behaviour as getShiftForStitching but always returns a shift of [0,0,0,0]
private getDeltaForStitching(c0:Collection,c1:Collection)->begin
  c0.each(i0,begin
    local result:=[c1.map((i1)->euklideanNorm(i1-i0)).min,[0,0,0,0]];
    result[0]=0 ? return note('Early abort ',result) orElse result : result;
  end,min);
end;

//*Stitches partitions in L, taking the periodicity of the config space into account
private stitchPartitions(L:List,expectedCount=1,allowShift:Boolean)->[L.each(p,p,|)];
private stitchPartitions(L:List,expectedCount>1,allowShift:Boolean)->L.size<=expectedCount ? L.map(::unique) : begin
  print('Stitching ',L.size,' => ',expectedCount,' partitions');
  local result:=L;
    local start:=scriptTime;
    local merges:=allowShift AND L.flatten.abs.max>250
                  ? [1..result.size-1].pEach(idx0,
                    [0..idx0-1]       .pEach(idx1,getShiftForStitching(result[idx0],result[idx1])||[idx0,idx1]),|).sort
                  : [1..result.size-1].pEach(idx0,
                    [0..idx0-1]       .pEach(idx1,getDeltaForStitching(result[idx0],result[idx1])||[idx0,idx1]),|).sort;
    print('Calculated ',result.size*(result.size-1)/2,' partition distances in ',scriptTime-start,' seconds');
    merges[0,0]>4
    ? return warn('Cancelled...') orElse result
    : void;

    local projSize:=result.size;
    while(merges.size>0 AND projSize>expectedCount,begin
      local merge:=merges.head; merges:=merges.tail;
      local idx0 :=merge[2,0];
      local idx1 :=merge[2,1];
      idx0==idx1 ? void : begin
        printf('Stitching %2d sets %2.2f%s ',projSize,merge[0].round(2),
          result.each(p,
          (index in merge[2]  ? '%5d*' :
                                '%5d ').format(p.size),&));
        local shift:=merge[1];
        local mergedPart:=result[idx0].union(result[idx1].map((x)->x+shift)).toList;
        result[idx0]:=mergedPart;
        result[idx1]:=[];
        projSize-=1;

        merges:=merges.each(m,
          begin
            local dist:=m[0];
            local shft:=m[1];
            local j0  :=m[2,0];
            local j1  :=m[2,1];
            j0=idx1 ? begin j0:=idx0; shft+=shift; end : void;
            j1=idx1 ? begin j1:=idx0; shft-=shift; end : void;
            [dist,shft,[j0,j1]];
          end);
      end;
    end);
    result:=result.filter((l)->l.size>0);
  result.map((part)->begin
    local shift:=-512*round(part.agg(+)/part.size/512);
    part.map((p)->p+shift).unique;
  end);
end;

//*Partitions and stitches a set of samples according to expected count.
//*If allowShift, stitching takes periodicity of the configuration space into account
private doPartition(L:List,expectedCount>1,allowShift:Boolean)->
  L.naivePartitioning.stitchPartitions(expectedCount,allowShift);

SERIALIZED_VOID:=#251'.';
datastore partitionedCurves:=[].toMap;
expectedNumberOfPartitions(i<4000)->2;
expectedNumberOfPartitions(i=4000)->3;
expectedNumberOfPartitions(i<=(2/3*7000))->4;
expectedNumberOfPartitions(i     )->2;

addPartitionedSamples(curveIndex:Int,granularity:Int,samples:List)->begin
  log('Partitioning raw data for curve index ',curveIndex);
  local parts:=samples
               .doPartition(expectedNumberOfPartitions(curveIndex),
                            granularity=0)
               .sort((x,y)->x.size<=y.size)
               .pMap(::sortCurve)
               .map((c)->c.head(max(1,c.size div 2)));
  local partitionedData:=[granularity,parts];
  partitionedCurves[curveIndex]:=partitionedData.serialize.compress;
  writeDataStores;
  note('Added samples for curve index ',curveIndex,' and updated data store');
end;

//*Returns the partitioned samples for an angle alpha=2*pi/7000 * i
getPartitionedSamples(i:Int)->((partitionedCurves[i] orElse SERIALIZED_VOID).decompress.deserialize orElse fail).{[$pd[0],$pd[1].map((c)->c|-c)]};

main('drop','part',index)->begin
  partitionedCurves[index      ]:=void;
  partitionedCurves[index.toInt]:=void;
end;

